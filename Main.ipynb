{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORK IN PROGRESS\n",
    "\n",
    "### Implementations\n",
    "\n",
    "- kNN\n",
    "- k-means\n",
    "- Decision Trees\n",
    "    - Gini \n",
    "    - Ent\n",
    "- Naive Bayse\n",
    "- Regression\n",
    "    - Simple Linear\n",
    "    - Multiple\n",
    "    - Logigistic\n",
    "- Perceptrons\n",
    "- FeedForawd Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy for Array operations\n",
    "import numpy\n",
    "\n",
    "#Pandas for nice data layout also will make it easer to implement the stats at the end\n",
    "import pandas\n",
    "\n",
    "from collections import Counter #for counting :D \n",
    "import math # maths \\(' ')\\\n",
    "import random\n",
    "\n",
    "#This is literally just to ensure our sublasses will be required to implement abstract methods\n",
    "from abc import ABCMeta, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Class\n",
    "\n",
    "So I have gone with a fairly boring name for our base class. its just ML because why not. \n",
    "This base class will wrap up some functionality that each of our methods should have.\n",
    "- Ensuring Similarity [Done]\n",
    "- Train test splitting [Done]\n",
    "- testing [Done]\n",
    "- Evaluation []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MachineLearning(metaclass=ABCMeta):\n",
    "    \n",
    "    def __init__(self, x, y, tts, thresh):\n",
    "        x_ = x.copy()\n",
    "        y_ = y\n",
    "        if type(x_) == pandas.DataFrame:\n",
    "            if 'labels' in x_.columns:\n",
    "                y_ = x_.pop('labels')\n",
    "            else:\n",
    "                if y_ is not None:\n",
    "                    raise RuntimeWarning(\"No 'labels' provided in Dataframe. Using the passed y\")\n",
    "            x_ = x.values\n",
    "        if type(x_) != numpy.ndarray:\n",
    "            x_ = numpy.array(x_)\n",
    "        if y_ is not None:\n",
    "            if type(y_) != numpy.ndarray:\n",
    "                y_ = numpy.array(y_)\n",
    "            if (len(x_) != len(y_)):\n",
    "                raise ValueError(\"X and Y should have the same amount of samples\")\n",
    "            if len(y_.shape) > 1:\n",
    "                raise ValueError(\"Y values should be singular\")\n",
    "        self.xtrain, self.ytrain, self.xtest, self.ytest = self.tts(x_, y_, tts, thresh)\n",
    "        self.num_samples = len(self.xtrain) - 1\n",
    "        self.num_features = len(self.xtrain[0]) - 1\n",
    "            \n",
    "        \n",
    "    def get_train(self):\n",
    "        #Get the Training Data in a nice way\n",
    "        zipped_ = zip([i for i in range(len(self.xtrain))], self.xtrain.transpose())\n",
    "        df_data = {}\n",
    "        for n, sample in zipped_:\n",
    "            df_data[\"train_feature\"+str(n)] = sample\n",
    "        if self.ytrain is not None:\n",
    "            df_data[\"train_labels\"] = self.ytrain\n",
    "        return pandas.DataFrame(df_data)\n",
    "            \n",
    "    def get_test(self):\n",
    "        testd = {}\n",
    "        if self.xtest is None:\n",
    "            raise RuntimeWarning(\"No Test Data\")\n",
    "        else:\n",
    "            zipped_ = zip([i for i in range(len(self.xtest))], self.xtest.transpose())\n",
    "            df_data = {}\n",
    "            for n, sample in zipped_:\n",
    "                testd[\"test_feature_\"+str(n)] = sample\n",
    "            if self.ytest is not None:\n",
    "                testd[\"test_labels\"] = self.ytest\n",
    "        return pandas.DataFrame(testd)\n",
    "    \n",
    "    def tts(self, x, y, tts = 0.8, thresh = 10):\n",
    "        '''\n",
    "        This function just splits the data\n",
    "        the threshold just checks whether or not to split the data\n",
    "        we don't need this but sometimes if you're just experimenting\n",
    "        you might have small datasets and not want to split it and you will want to Test\n",
    "        on the Training (Even if it screws the evaluation)\n",
    "        '''\n",
    "        xtrain, ytrain, xtest, ytest = None, None, None, None\n",
    "        xlen = len(x)\n",
    "        train_len = round(xlen * tts)\n",
    "        test_len = xlen - train_len\n",
    "        if y is not None:\n",
    "            if thresh > test_len:\n",
    "                xtrain, xtest = x.copy(), x.copy()\n",
    "                ytrain, ytest = y.copy(), y.copy()\n",
    "            else:\n",
    "                xtrain, xtest = x.copy()[0:train_len], x.copy()[train_len:]\n",
    "                ytrain, ytest = y.copy()[0:train_len], y.copy()[train_len:]\n",
    "        else:\n",
    "            xtrain, xtest = x.copy(), x.copy()\n",
    "        return xtrain, ytrain, xtest, ytest\n",
    "        \n",
    "    @abstractmethod\n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, x):\n",
    "        pass\n",
    "        \n",
    "    def test(self):\n",
    "        predictions = self.predict(self.xtest)\n",
    "        test_res = {\"predictions\": predictions}\n",
    "        if self.ytest is not None:\n",
    "            test_res[\"Actual\"] = self.ytest\n",
    "        return pandas.DataFrame(test_res)\n",
    "    \n",
    "    def results(self):\n",
    "        res = self.test()\n",
    "        tp = len(res[(res[\"Actual\"] == 1) & (res[\"predictions\"] == 1)])\n",
    "        fn = len(res[(res[\"Actual\"] == 1) & (res[\"predictions\"] == 0)])\n",
    "        fp = len(res[(res[\"Actual\"] == 0) & (res[\"predictions\"] == 1)])\n",
    "        tn = len(res[(res[\"Actual\"] == 0) & (res[\"predictions\"] == 0)])\n",
    "        return tp, fn, fp, tn\n",
    "    \n",
    "    def stats(self):\n",
    "        tp, fn, fp, tn =  self.results()\n",
    "        tp, fn, fp, tn = tp+1, fn+1, fp+1, tn+1 \n",
    "        acc = (tp + tn) / (tp + fn + fp + tn)\n",
    "        prec = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        speci = tn / (tn + fp)\n",
    "        # ð‘­ðŸ = ðŸ âˆ— (ð’‘ð’“ð’†ð’„ð’Šð’”ð’Šð’ð’ âˆ— ð’“ð’†ð’„ð’‚ð’ð’) / (ð’‘ð’“ð’†ð’„ð’Šð’”ð’Šð’ð’ + ð’“ð’†ð’„ð’‚ð’ð’)\n",
    "        f1 = 2 * (prec * recall) / (prec + recall)\n",
    "        return {\n",
    "            \"Acuuracy\": round(acc,3),\n",
    "            \"Precision\": round(prec,3),\n",
    "            \"Recall\": round(recall,3),\n",
    "            \"Specificity\": round(speci,3),\n",
    "            \"F1\": round(f1,3)\n",
    "        }\n",
    "    \n",
    "    def confusion_matrix(self):\n",
    "        tp, fn, fp, tn = self.results()\n",
    "        d = {\n",
    "            \"pos\": [tp, fp],\n",
    "            \"neg\": [fn, tn]\n",
    "        }\n",
    "        ret = pandas.DataFrame(d)\n",
    "        ret.rename(index={0: \"pos\", 1: \"neg\"})\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNN(MachineLearning):\n",
    "    \n",
    "    def __init__(self, x, y=None, k=3, weighted=False, dist_type=\"manhattan\", tts=0.8, thresh=10):\n",
    "        super(kNN, self).__init__(x, y, tts=0.8, thresh=10)\n",
    "        self.k = k\n",
    "        self.weighted = weighted\n",
    "        self.dist_type = dist_type\n",
    "        self.distance_types = [\"manhattan\", \"euclid\"]\n",
    "        if self.dist_type not in self.distance_types:\n",
    "            raise RuntimeError(\"You need to use an actual distance type (see kNN.distance_types)\")\n",
    "        if self.k > self.num_samples:\n",
    "            raise RuntimeError(\"k can't be greater than the number of samples\")\n",
    "        if self.ytrain is None:\n",
    "            raise RuntimeError(\"K-Nearest Neighbours needs labels\")\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        #For K-neighbours we don't need to fit since we predict on the samples.\n",
    "        pass\n",
    "    \n",
    "    def distance(self, a, b):\n",
    "        tot = 0\n",
    "        for i in range(self.num_features):\n",
    "            if self.dist_type == \"manhattan\":\n",
    "                tot += abs(a[i] - b[i])\n",
    "            elif self.dist_type == \"euclid\":\n",
    "                tot += ((a[i] - b[i]) ** 2)\n",
    "        if self.dist_type == \"euclid\":\n",
    "            tot = math.sqrt(tot)\n",
    "        return tot\n",
    "    \n",
    "    def calc_weighted_label(self, labels, weights):\n",
    "        tot_pos, tot_neg = 0, 0\n",
    "        for i in range(self.k):\n",
    "            if labels[i] == 0:\n",
    "                tot_neg += weights[i]\n",
    "            else:\n",
    "                tot_pos += weights[i]\n",
    "        ret = 0\n",
    "        if tot_pos > tot_neg:\n",
    "            ret = 1\n",
    "        if tot_pos == tot_neg:\n",
    "            ret = 1 if (random.random() > 0.5) else 0\n",
    "        return ret\n",
    "    \n",
    "    def calc_knn(self, dists):\n",
    "        ret = 0\n",
    "        s = sorted(dists)\n",
    "        labs, weights = [], []\n",
    "        for i in range(self.k):\n",
    "            l = self.ytrain[dists.index(s[i])]\n",
    "            labs.append(l)\n",
    "            weights.append(s[i])\n",
    "        if self.weighted:\n",
    "            ret = self.calc_weighted_label(labs, weights)\n",
    "        else:\n",
    "            c = Counter(labs)\n",
    "            ret = c.most_common()[0][0]\n",
    "        return ret\n",
    "    \n",
    "    def knn_sample(self, n):\n",
    "        distances = []\n",
    "        for i in range(self.num_samples):\n",
    "            dist = self.distance(self.xtrain[i], n)\n",
    "            distances.append(dist)\n",
    "        return self.calc_knn(distances)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        ret = []\n",
    "        if type(x) != numpy.ndarray:\n",
    "            if type(x) != list:\n",
    "                raise RuntimeError(\"You need to provide the values as a list\")\n",
    "        for samp in x:\n",
    "            ret.append(self.knn_sample(samp))\n",
    "        return numpy.array(ret)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"./diabetes.csv\")\n",
    "df = df.rename(columns={\"Outcome\": \"labels\"})\n",
    "labs = df.pop(\"labels\") \n",
    "df = (df - df.mean())/df.std(ddof=0)\n",
    "df[\"labels\"] = labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Acuuracy': 0.703, 'Precision': 0.609, 'Recall': 0.491, 'Specificity': 0.822, 'F1': 0.544}\n",
      "{'Acuuracy': 0.734, 'Precision': 0.674, 'Recall': 0.509, 'Specificity': 0.861, 'F1': 0.58}\n",
      "{'Acuuracy': 0.741, 'Precision': 0.682, 'Recall': 0.526, 'Specificity': 0.861, 'F1': 0.594}\n",
      "{'Acuuracy': 0.715, 'Precision': 0.658, 'Recall': 0.439, 'Specificity': 0.871, 'F1': 0.526}\n"
     ]
    }
   ],
   "source": [
    "knn = kNN(df, k=8)\n",
    "print(knn.stats())\n",
    "knn = kNN(df, k=8, weighted=True)\n",
    "print(knn.stats())\n",
    "knn = kNN(df, k=8, dist_type=\"euclid\")\n",
    "print(knn.stats())\n",
    "knn = kNN(df, k=8, weighted=True, dist_type=\"euclid\")\n",
    "print(knn.stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpass1",
   "language": "python",
   "name": "mlpass1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
