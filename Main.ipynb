{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORK IN PROGRESS\n",
    "\n",
    "### Implementations\n",
    "\n",
    "Supervised\n",
    "- kNN\n",
    "- Decision Trees\n",
    "    - Gini \n",
    "    - Ent\n",
    "- Naive Bayse\n",
    "- Regression\n",
    "    - Simple Linear\n",
    "    - Multiple\n",
    "    - Logigistic\n",
    "- Perceptrons\n",
    "- FeedForawd Neural Nets\n",
    "\n",
    "Unsupervised:\n",
    "- k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy for Array operations\n",
    "import numpy\n",
    "\n",
    "#Pandas for nice data layout also will make it easer to implement the stats at the end\n",
    "import pandas\n",
    "\n",
    "from collections import Counter #for counting :D \n",
    "import math # ~~maths~~ \n",
    "import random # for when we are feeling random 0-o\n",
    "\n",
    "#This is literally just to ensure our sublasses will be required to implement abstract methods\n",
    "from abc import ABCMeta, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Class\n",
    "\n",
    "So I have gone with a fairly boring name for our base class. its just ML because why not. \n",
    "This base class will wrap up some functionality that each of our methods should have.\n",
    "- Ensuring Similarity [Done]\n",
    "- Train test splitting [Done]\n",
    "- testing [Done]\n",
    "- Evaluation []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MachineLearning(metaclass=ABCMeta):\n",
    "    \n",
    "    def __init__(self, x, y, tts, thresh):\n",
    "        x_ = x.copy()\n",
    "        y_ = y\n",
    "        if type(x) == pandas.DataFrame:\n",
    "            if 'labels' in x_.columns:\n",
    "                y_ = x_.pop('labels')\n",
    "            else:\n",
    "                if y_ is not None:\n",
    "                    raise RuntimeWarning(\"No 'labels' provided in Dataframe. Using the passed y\")\n",
    "            x_ = x_.values\n",
    "        if type(x_) != numpy.ndarray:\n",
    "            x_ = numpy.array(x_)\n",
    "        if y_ is not None:\n",
    "            if type(y_) != numpy.ndarray:\n",
    "                y_ = numpy.array(y_)\n",
    "            if (len(x_) != len(y_)):\n",
    "                raise ValueError(\"X and Y should have the same amount of samples\")\n",
    "            if len(y_.shape) > 1:\n",
    "                raise ValueError(\"Y values should be singular\")\n",
    "        self.xtrain, self.ytrain, self.xtest, self.ytest = self.__tts__(x_, y_, tts, thresh)\n",
    "        self.num_samples = len(self.xtrain) - 1\n",
    "        self.num_features = len(self.xtrain[0]) - 1\n",
    "            \n",
    "        \n",
    "    def get_train(self):\n",
    "        #Get the Training Data in a nice way\n",
    "        zipped_ = zip([i for i in range(len(self.xtrain))], self.xtrain.transpose())\n",
    "        df_data = {}\n",
    "        for n, sample in zipped_:\n",
    "            df_data[\"train_feature\"+str(n)] = sample\n",
    "        if self.ytrain is not None:\n",
    "            df_data[\"train_labels\"] = self.ytrain\n",
    "        return pandas.DataFrame(df_data)\n",
    "            \n",
    "    def get_test(self):\n",
    "        testd = {}\n",
    "        if self.xtest is None:\n",
    "            raise RuntimeWarning(\"No Test Data\")\n",
    "        else:\n",
    "            zipped_ = zip([i for i in range(len(self.xtest))], self.xtest.transpose())\n",
    "            df_data = {}\n",
    "            for n, sample in zipped_:\n",
    "                testd[\"test_feature_\"+str(n)] = sample\n",
    "            if self.ytest is not None:\n",
    "                testd[\"test_labels\"] = self.ytest\n",
    "        return pandas.DataFrame(testd)\n",
    "    \n",
    "    def __tts__(self, x, y, tts = 0.8, thresh = 10):\n",
    "        '''\n",
    "        This function just splits the data\n",
    "        the threshold just checks whether or not to split the data\n",
    "        we don't need this but sometimes if you're just experimenting\n",
    "        you might have small datasets and not want to split it and you will want to Test\n",
    "        on the Training (Even if it screws the evaluation)\n",
    "        '''\n",
    "        xtrain, ytrain, xtest, ytest = None, None, None, None\n",
    "        xlen = len(x)\n",
    "        train_len = round(xlen * tts)\n",
    "        test_len = xlen - train_len\n",
    "        if y is not None:\n",
    "            if thresh > test_len:\n",
    "                xtrain, xtest = x.copy(), x.copy()\n",
    "                ytrain, ytest = y.copy(), y.copy()\n",
    "            else:\n",
    "                xtrain, xtest = x.copy()[0:train_len], x.copy()[train_len:]\n",
    "                ytrain, ytest = y.copy()[0:train_len], y.copy()[train_len:]\n",
    "        else:\n",
    "            xtrain, xtest = x.copy(), x.copy()\n",
    "        return xtrain, ytrain, xtest, ytest\n",
    "        \n",
    "    @abstractmethod\n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, x):\n",
    "        pass\n",
    "    \n",
    "    def __can_test__(self):\n",
    "        if self.ytest is None:\n",
    "            raise RuntimeError(\"No test labels\")\n",
    "        return True\n",
    "    \n",
    "    def predict_testx(self):\n",
    "        predictions = self.predict(self.xtest)\n",
    "        test_res = {\"predictions\": predictions}\n",
    "        return test_res\n",
    "    \n",
    "    def test(self):\n",
    "        self.__can_test__()\n",
    "        test_res = self.predict_testx()\n",
    "        test_res[\"Actual\"] = self.ytest\n",
    "        return pandas.DataFrame(test_res)\n",
    "    \n",
    "    def binary_results(self):\n",
    "        self.__can_test__()\n",
    "        res = self.test()\n",
    "        tp = len(res[(res[\"Actual\"] == 1) & (res[\"predictions\"] == 1)])\n",
    "        fn = len(res[(res[\"Actual\"] == 1) & (res[\"predictions\"] == 0)])\n",
    "        fp = len(res[(res[\"Actual\"] == 0) & (res[\"predictions\"] == 1)])\n",
    "        tn = len(res[(res[\"Actual\"] == 0) & (res[\"predictions\"] == 0)])\n",
    "        return tp, fn, fp, tn\n",
    "    \n",
    "    def binary_stats(self):\n",
    "        self.__can_test__()\n",
    "        tp, fn, fp, tn =  self.binary_results()\n",
    "        tp, fn, fp, tn = tp+1, fn+1, fp+1, tn+1 \n",
    "        acc = (tp + tn) / (tp + fn + fp + tn)\n",
    "        prec = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        speci = tn / (tn + fp)\n",
    "        # 𝑭𝟏 = 𝟐 ∗ (𝒑𝒓𝒆𝒄𝒊𝒔𝒊𝒐𝒏 ∗ 𝒓𝒆𝒄𝒂𝒍𝒍) / (𝒑𝒓𝒆𝒄𝒊𝒔𝒊𝒐𝒏 + 𝒓𝒆𝒄𝒂𝒍𝒍)\n",
    "        f1 = 2 * (prec * recall) / (prec + recall)\n",
    "        return {\n",
    "            \"Acuuracy\": round(acc,3),\n",
    "            \"Precision\": round(prec,3),\n",
    "            \"Recall\": round(recall,3),\n",
    "            \"Specificity\": round(speci,3),\n",
    "            \"F1\": round(f1,3)\n",
    "        }\n",
    "    \n",
    "    def confusion_matrix(self):\n",
    "        self.__can_test__()\n",
    "        tp, fn, fp, tn = self.results()\n",
    "        d = {\n",
    "            \"pos\": [tp, fp],\n",
    "            \"neg\": [fn, tn]\n",
    "        }\n",
    "        ret = pandas.DataFrame(d)\n",
    "        ret.rename(index={0: \"pos\", 1: \"neg\"})\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNN(MachineLearning):\n",
    "    \n",
    "    def __init__(self, x, y=None, k=3, weighted=False, dist_type=\"manhattan\", tts=0.8, thresh=10):\n",
    "        super(kNN, self).__init__(x, y, tts=0.8, thresh=10)\n",
    "        self.k = k\n",
    "        self.weighted = weighted\n",
    "        self.dist_type = dist_type\n",
    "        self.distance_types = [\"manhattan\", \"euclid\"]\n",
    "        if self.dist_type not in self.distance_types:\n",
    "            raise RuntimeError(\"You need to use an actual distance type (see kNN.distance_types)\")\n",
    "        if self.k > self.num_samples:\n",
    "            raise RuntimeError(\"k can't be greater than the number of samples\")\n",
    "        if self.ytrain is None:\n",
    "            raise RuntimeError(\"K-Nearest Neighbours needs labels\")\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        #For K-neighbours we don't need to fit since we predict on the samples.\n",
    "        pass\n",
    "    \n",
    "    def distance(self, a, b):\n",
    "        tot = 0\n",
    "        for i in range(self.num_features):\n",
    "            if self.dist_type == \"manhattan\":\n",
    "                tot += abs(a[i] - b[i])\n",
    "            elif self.dist_type == \"euclid\":\n",
    "                tot += ((a[i] - b[i]) ** 2)\n",
    "        if self.dist_type == \"euclid\":\n",
    "            tot = math.sqrt(tot)\n",
    "        return tot\n",
    "    \n",
    "    def calc_weighted_label(self, labels, weights):\n",
    "        tot_pos, tot_neg = 0, 0\n",
    "        for i in range(self.k):\n",
    "            if labels[i] == 0:\n",
    "                tot_neg += weights[i]\n",
    "            else:\n",
    "                tot_pos += weights[i]\n",
    "        ret = 0\n",
    "        if tot_pos > tot_neg:\n",
    "            ret = 1\n",
    "        if tot_pos == tot_neg:\n",
    "            ret = 1 if (random.random() > 0.5) else 0\n",
    "        return ret\n",
    "    \n",
    "    def calc_knn(self, dists):\n",
    "        ret = 0\n",
    "        s = sorted(dists)\n",
    "        labs, weights = [], []\n",
    "        for i in range(self.k):\n",
    "            l = self.ytrain[dists.index(s[i])]\n",
    "            labs.append(l)\n",
    "            weights.append(s[i])\n",
    "        if self.weighted:\n",
    "            ret = self.calc_weighted_label(labs, weights)\n",
    "        else:\n",
    "            c = Counter(labs)\n",
    "            ret = c.most_common()[0][0]\n",
    "        return ret\n",
    "    \n",
    "    def knn_sample(self, n):\n",
    "        distances = []\n",
    "        for i in range(self.num_samples):\n",
    "            dist = self.distance(self.xtrain[i], n)\n",
    "            distances.append(dist)\n",
    "        return self.calc_knn(distances)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        ret = []\n",
    "        if type(x) != numpy.ndarray:\n",
    "            if type(x) != list:\n",
    "                raise RuntimeError(\"You need to provide the values as a list\")\n",
    "        for samp in x:\n",
    "            ret.append(self.knn_sample(samp))\n",
    "        return numpy.array(ret)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"./diabetes.csv\")\n",
    "df = df.rename(columns={\"Outcome\": \"labels\"})\n",
    "labs = df.pop(\"labels\") \n",
    "df = (df - df.mean())/df.std(ddof=0)\n",
    "df[\"labels\"] = labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Acuuracy': 0.747, 'Precision': 0.681, 'Recall': 0.561, 'Specificity': 0.851, 'F1': 0.615}\n",
      "{'Acuuracy': 0.715, 'Precision': 0.63, 'Recall': 0.509, 'Specificity': 0.832, 'F1': 0.563}\n",
      "{'Acuuracy': 0.722, 'Precision': 0.644, 'Recall': 0.509, 'Specificity': 0.842, 'F1': 0.569}\n",
      "{'Acuuracy': 0.709, 'Precision': 0.641, 'Recall': 0.439, 'Specificity': 0.861, 'F1': 0.521}\n"
     ]
    }
   ],
   "source": [
    "knn = kNN(df, k=8)\n",
    "print(knn.binary_stats())\n",
    "knn = kNN(df, k=8, weighted=True)\n",
    "print(knn.binary_stats())\n",
    "knn = kNN(df, k=8, dist_type=\"euclid\")\n",
    "print(knn.binary_stats())\n",
    "knn = kNN(df, k=8, weighted=True, dist_type=\"euclid\")\n",
    "print(knn.binary_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(MachineLearning):\n",
    "    \n",
    "    def __init__(self, x, y=None, impurity_measure=\"gini\", max_depth=3, tts=0.8, thresh=10):\n",
    "        super(DecisionTree, self).__init__(x, y, tts=0.8, thresh=10)\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "        if self.ytrain is None:\n",
    "            raise RuntimeError(\"Decision Tree needs labels\")\n",
    "        self.impurity_measure = impurity_measure\n",
    "        \n",
    "        self.__f__ = None\n",
    "        if impurity_measure == \"gini\":\n",
    "            self.__f__  = lambda x: (x * (1 - x))\n",
    "        elif impurity_measure == \"entropy\":\n",
    "            self.__f__  = lambda x: (-1 * x * math.log(x, 2))\n",
    "        \n",
    "        self.__rename__  = None\n",
    "        self.__df__ = pandas.DataFrame(self.xtrain)\n",
    "        if type(x) == pandas.DataFrame:\n",
    "            z = zip(list(df.columns.factorize()[0]),\n",
    "                   list(df.columns.factorize()[1]))\n",
    "            d = {key: value for (key, value) in z} \n",
    "            self.__df__ = self.__df__.rename(columns=d)\n",
    "            self.__rename__ = d\n",
    "        self.__cols__ = self.__df__.columns\n",
    "        self.__df__[\"labels\"] = self.ytrain\n",
    "        self.__classes__ = numpy.unique(self.__df__[\"labels\"])\n",
    "        self.fit()\n",
    "        \n",
    "        \n",
    "    def __feature_split__(self, dataset, feature):\n",
    "        split = dataset[feature].median()\n",
    "        above = dataset[dataset[feature] >= split]\n",
    "        below = dataset[dataset[feature] < split]\n",
    "        return above, below\n",
    "    \n",
    "    def __feature_impurity__(self, dataset, feature):\n",
    "        tot = len(dataset)\n",
    "        ab, be = self.__feature_split__(dataset, feature)\n",
    "        ab_imp = ( (len(ab)/tot) * self.__impurity__(Counter(ab[\"labels\"])))\n",
    "        be_imp = ( (len(be)/tot) * self.__impurity__(Counter(be[\"labels\"])))\n",
    "        return (ab_imp + be_imp)\n",
    "        \n",
    "    def __impurity__(self, counter):\n",
    "        total = 10000\n",
    "        tot_e = sum(counter.values())\n",
    "        if tot_e != 0:\n",
    "            total = 0\n",
    "            for e in self.__classes__:\n",
    "                p_e = (counter[e]/tot_e)\n",
    "            total += (0 if p_e == 0 else self.__f__(p_e))\n",
    "        return float(total)\n",
    "    \n",
    "    def __best_feature__(self, dataset):\n",
    "        h_s = self.__impurity__(Counter(dataset[\"labels\"]))\n",
    "        feature = self.__cols__[0]\n",
    "        feature_imp = -1\n",
    "        for f in self.__cols__ :\n",
    "            imp_f = self.__feature_impurity__(dataset, f)\n",
    "            f_imp = (h_s - imp_f)\n",
    "            if f_imp > feature_imp:\n",
    "                feature = f\n",
    "                feature_imp = f_imp\n",
    "        return feature\n",
    "    \n",
    "    def __node_info__(self, dataset, d):\n",
    "        ret = None\n",
    "        if len(dataset) > 0:\n",
    "            c = Counter(dataset[\"labels\"])\n",
    "            impurity = self.__impurity__(c) \n",
    "            ret =  {\n",
    "                \"depth\": d,\n",
    "                \"classes\": dict(c),\n",
    "                \"impurity\": impurity,\n",
    "                \"leaf\": True\n",
    "            }\n",
    "            if (impurity != 0):\n",
    "                split_feat = self.__best_feature__(dataset)\n",
    "                bar = dataset[split_feat].median()\n",
    "                question = split_feat+\" >= \"+str(bar) \n",
    "                ret[\"leaf\"] = False\n",
    "                ret[\"split_feature\"] = split_feat\n",
    "                ret[\"above\"] = bar\n",
    "                ret[\"question\"] = question\n",
    "        if ret[\"leaf\"]:\n",
    "            ret[\"class\"] = c.most_common()[0][0]\n",
    "        return ret\n",
    "        \n",
    "    def __create_tree__(self, dataset, depth):\n",
    "        ds = dataset.copy()\n",
    "        node = self.__node_info__(ds, depth)\n",
    "        if (node is not None) and (node[\"impurity\"] != 0):\n",
    "            a, b = self.__feature_split__(ds, node[\"split_feature\"])\n",
    "            if depth != self.max_depth:  \n",
    "                if len(a) > 0:\n",
    "                    node[\"True\"] = self.__create_tree__(a, (depth + 1))\n",
    "                if len(b) > 0:\n",
    "                    node[\"False\"] = self.__create_tree__(b, (depth + 1))\n",
    "            else:\n",
    "                node[\"leaf\"] = True\n",
    "        return node\n",
    "            \n",
    "    def fit(self):\n",
    "        top_node = self.__create_tree__(self.__df__.copy(), 0)\n",
    "        self.tree = top_node\n",
    "    \n",
    "    def predict_sample(self, x):\n",
    "        curr_q = self.tree\n",
    "        while (curr_q[\"impurity\"] != 0.0):\n",
    "            q = curr_q[\"split_feature\"]\n",
    "            a = curr_q[\"above\"]\n",
    "            curr_q = curr_q[str((x[q] >= a).item())]\n",
    "        return curr_q[\"class\"]\n",
    "    \n",
    "    def predict(self, x):\n",
    "        ret = []\n",
    "        l = None\n",
    "        for samp in x:\n",
    "            l = pandas.DataFrame(numpy.array([samp]))\n",
    "            if self.__rename__ is not None:   \n",
    "                l = l.rename(columns=self.__rename__)\n",
    "            ret.append(self.predict_sample(l))\n",
    "        return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pear</td>\n",
       "      <td>Pear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pear</td>\n",
       "      <td>Pear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pear</td>\n",
       "      <td>Pear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pear</td>\n",
       "      <td>Pear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predictions Actual\n",
       "0       Apple  Apple\n",
       "1        Pear   Pear\n",
       "2       Apple  Apple\n",
       "3        Pear   Pear\n",
       "4        Pear   Pear\n",
       "5       Apple  Apple\n",
       "6        Pear   Pear\n",
       "7       Apple  Apple\n",
       "8       Apple  Apple\n",
       "9       Apple  Apple"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv(\"./ApplesPears.csv\")\n",
    "df = df.rename(columns={\"Class\": \"labels\"})\n",
    "df[\"Taste\"] = df[\"Taste\"].apply(lambda x: [\"Sweet\", \"Sour\", \"Tart\"].index(x))\n",
    "dt = DecisionTree(df)\n",
    "dt.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayse(MachineLearning):\n",
    "    \n",
    "    def __init__(self, x, y=None, feat_thresh=4, tts=0.8, thresh=10):\n",
    "        super(NaiveBayse, self).__init__(x, y, tts=0.8, thresh=10)\n",
    "        self.probs = None\n",
    "        self.__rename__ = None\n",
    "        self.__feature_threshold__ = 4\n",
    "        self.__df__ = pandas.DataFrame(self.xtrain)\n",
    "        if type(x) == pandas.DataFrame:\n",
    "            z = zip(list(df.columns.factorize()[0]),\n",
    "                   list(df.columns.factorize()[1]))\n",
    "            d = {key: value for (key, value) in z} \n",
    "            self.__rename__ = d\n",
    "            self.__df__ = self.__df__.rename(columns=self.__rename__)\n",
    "        else:\n",
    "            raise RuntimeError(\"Please provide a Dataframe to Naive Bayse\")\n",
    "        self.__cols__ = self.__df__.columns\n",
    "        self.__df__[\"labels\"] = self.ytrain\n",
    "        self.__classes__ = numpy.unique(self.__df__[\"labels\"])\n",
    "        self.fit()\n",
    "\n",
    "    def gaus_pdf(self, x, mean, stdev):\n",
    "        exponent = math.exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "        return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "\n",
    "    def comp_prob(self, arr):\n",
    "        mean = numpy.mean(arr)\n",
    "        stdev = numpy.std(arr)\n",
    "        return lambda x: self.gaus_pdf(x, mean, stdev)\n",
    "\n",
    "    def simple_prob(self, arr):\n",
    "        dummies = pandas.get_dummies(pandas.DataFrame(arr))\n",
    "        p = {}\n",
    "        for col in dummies.columns:\n",
    "            p[col] = dummies[col].sum() / len(dummies)\n",
    "        return p\n",
    "\n",
    "    def f_prob(self, f, c):\n",
    "        ret = None\n",
    "        df_ = self.__df__[self.__df__[\"labels\"] == c]\n",
    "        if len(self.__df__[f].unique()) < self.__feature_threshold__:\n",
    "            ret = self.simple_prob(df_[f])\n",
    "        else:\n",
    "            ret = self.comp_prob(df_[f])\n",
    "        return ret\n",
    "\n",
    "    def fit(self):\n",
    "        probabilties = []\n",
    "        for c in self.__classes__:\n",
    "            p_class = (len(self.__df__[self.__df__[\"labels\"] == c])/len(self.__df__))\n",
    "            probs = {\n",
    "                \"class\": c,\n",
    "                \"probability\": p_class\n",
    "            }\n",
    "            for f in self.__cols__:\n",
    "                probs[f] = self.f_prob(f, c)\n",
    "            probabilties.append(probs)\n",
    "        self.probs = probabilties\n",
    "        \n",
    "    def __samp_probabilities__(self, x):\n",
    "        class_probs = []\n",
    "        for c in probs:\n",
    "            p = c[\"probability\"]\n",
    "            for f in list(c.keys())[2:]:\n",
    "                if type(c[f]) is dict:\n",
    "                    if (f+\"_\"+x[\"Greeness\"].item()) in c[f]:\n",
    "                        p *= c[f][f+\"_\"+x[\"Greeness\"].item()]\n",
    "                    else:\n",
    "                        p *= 0.001\n",
    "                else:\n",
    "                    p *= c[f](x[f])\n",
    "            class_probs.append(p)\n",
    "        return class_probs\n",
    "        \n",
    "    def predict_sample(self, x):\n",
    "        c_probs = self.__samp_probabilities__(x)\n",
    "        norm_probs = [(i/(sum(class_probs)) ) for i in c_probs]\n",
    "        class_ = self.probs[norm_probs.index(max(norm_probs))][\"class\"]\n",
    "        return class_\n",
    "    \n",
    "    def predict(self, x):\n",
    "        ret = []\n",
    "        l = None\n",
    "        for samp in x:\n",
    "            l = pandas.DataFrame(numpy.array([samp]))\n",
    "            if self.__rename__ is not None:   \n",
    "                l = l.rename(columns=self.__rename__)\n",
    "            ret.append(self.predict_sample(l))\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple',\n",
       " 'Pear',\n",
       " 'Apple',\n",
       " 'Pear',\n",
       " 'Pear',\n",
       " 'Apple',\n",
       " 'Pear',\n",
       " 'Apple',\n",
       " 'Apple',\n",
       " 'Apple']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv(\"./ApplesPears.csv\")\n",
    "df = df.rename(columns={\"Class\": \"labels\"})\n",
    "df[\"Greeness\"] = df[\"Greeness\"].apply(lambda x: \"pale\" if x < 190 else (\"medium\" if x < 110 else \"Dark\"))\n",
    "nb = NaiveBayse(df)\n",
    "probs = nb.probs\n",
    "nb.predict(nb.xtest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpass1",
   "language": "python",
   "name": "mlpass1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
